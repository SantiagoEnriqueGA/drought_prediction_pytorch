{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drought Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General purpose libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Scikit-learn libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, ParameterGrid\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, roc_curve, auc, cohen_kappa_score)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Imbalanced-learn libraries for handling imbalanced datasets\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule, NearMiss\n",
    "\n",
    "# PyTorch libraries for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torchviz import make_dot\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Scipy library for statistical functions\n",
    "from scipy.stats import uniform\n",
    "# Base classes for custom estimators in scikit-learn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check device, use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drought_df =  pd.read_csv('data/all_timeseries.csv')\n",
    "\n",
    "# Load training and testing data from a pickle file\n",
    "with open('data/Xy_trainTest.pkl', 'rb') as f:\n",
    "    # Unpickle the data into training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation split ratio\n",
    "val_split_ratio = 0.2\n",
    "val_size = int(len(train_dataset) * val_split_ratio)\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural Network Classes/Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class: DroughtClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroughtClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network classifier for drought prediction.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): The number of input features.\n",
    "        hidden_sizes (list of int): A list containing the sizes of the hidden layers.\n",
    "        output_size (int): The number of output classes.\n",
    "        dropout_prob (float, optional): The probability of an element to be zeroed in dropout. Default is 0.5.\n",
    "\n",
    "    Attributes:\n",
    "        layers (nn.ModuleList): A list of linear layers.\n",
    "        dropout (nn.Dropout): Dropout layer for regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_prob=0.5):\n",
    "        super(DroughtClassifier, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        # Apply each layer followed by ReLU activation and dropout, except the last layer\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.dropout(F.relu(layer(x)))\n",
    "        # Apply the last layer without activation or dropout\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class: EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after a given patience.\n",
    "\n",
    "    Args:\n",
    "        patience (int, optional): How long to wait after last time validation loss improved. Default is 5.\n",
    "        delta (float, optional): Minimum change in the monitored quantity to qualify as an improvement. Default is 0.\n",
    "\n",
    "    Attributes:\n",
    "        patience (int): How long to wait after last time validation loss improved.\n",
    "        delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        best_loss (float): Best recorded validation loss.\n",
    "        counter (int): Counter for how many epochs have passed since the last improvement.\n",
    "        early_stop (bool): Whether early stopping is triggered.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        \"\"\"\n",
    "        Checks if the validation loss has improved and updates the counter and early stop flag accordingly.\n",
    "\n",
    "        Args:\n",
    "            val_loss (float): The current validation loss.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            # If the validation loss has improved (by more than delta), reset the counter\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            # If the validation loss has not improved, increment the counter\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                # If the counter exceeds the patience, set the early stop flag\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: get_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get a unique log directory\n",
    "def get_log_dir(base_dir='runs'):\n",
    "    \"\"\"\n",
    "    Generates a unique log directory path based on the current date and time.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str, optional): The base directory where logs will be saved. Default is 'runs'.\n",
    "\n",
    "    Returns:\n",
    "        str: A unique directory path for saving logs.\n",
    "    \"\"\"\n",
    "    # Get the current date and time as a formatted string\n",
    "    current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    # Create a log directory path by combining the base directory and the current time\n",
    "    log_dir = os.path.join(base_dir, current_time)\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, patience=5, log_dir=None, hparams=None):\n",
    "    \"\"\"\n",
    "    Trains the model with early stopping and logs metrics to TensorBoard.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to be trained.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer for training.\n",
    "        scheduler (torch.optim.lr_scheduler): Learning rate scheduler.\n",
    "        num_epochs (int, optional): The maximum number of epochs for training. Default is 25.\n",
    "        patience (int, optional): The number of epochs with no improvement after which training will be stopped. Default is 5.\n",
    "        log_dir (str, optional): The directory to save TensorBoard logs. If None, a new directory will be created.\n",
    "        hparams (dict, optional): Hyperparameters to log.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if log_dir is None:\n",
    "        log_dir = get_log_dir()                         # Create a unique log directory if not provided\n",
    "    writer = SummaryWriter(log_dir=log_dir)             # Initialize TensorBoard writer\n",
    "    early_stopping = EarlyStopping(patience=patience)   # Initialize early stopping\n",
    "    \n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()                # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
    "            \n",
    "            optimizer.zero_grad() # Zero the parameter gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)             # Accumulate loss\n",
    "            _, preds = torch.max(outputs, 1)                         # Get predictions\n",
    "            correct_predictions += torch.sum(preds == labels).item() # Count correct predictions\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)             # Calculate average loss for this epoch\n",
    "        epoch_accuracy = correct_predictions / len(train_loader.dataset)  # Calculate accuracy for this epoch\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        val_running_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        with torch.no_grad():                                           # Disable gradient computation for validation\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)   # Move inputs and labels to GPU\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item() * inputs.size(0)        # Accumulate validation loss\n",
    "                _, preds = torch.max(outputs, 1)                        # Get predictions\n",
    "                val_correct_predictions += torch.sum(preds == labels).item() # Count correct predictions\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader.dataset)               # Calculate average validation loss\n",
    "        val_accuracy = val_correct_predictions / len(val_loader.dataset)    # Calculate validation accuracy\n",
    "        \n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)                      # Log training loss\n",
    "        writer.add_scalar('Loss/validation', val_loss, epoch)                   # Log validation loss\n",
    "        writer.add_scalar('Accuracy/train', epoch_accuracy, epoch)              # Log training accuracy\n",
    "        writer.add_scalar('Accuracy/validation', val_accuracy, epoch)           # Log validation accuracy\n",
    "        writer.add_scalar('Learning_Rate', scheduler.get_last_lr()[0], epoch)   # Log learning rate\n",
    "        \n",
    "        # Print metrics for the current epoch\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Check early stopping criteria\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Log hyperparameters and final metrics to TensorBoard\n",
    "    if hparams is not None:\n",
    "        writer.add_hparams(hparams, {'hparam/accuracy': val_accuracy, 'hparam/loss': val_loss})\n",
    "    print('Training complete')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset and prints the test loss and accuracy.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained neural network model to be evaluated.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        criterion (nn.Module): The loss function.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():                                           # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)   # Move inputs and labels to GPU\n",
    "\n",
    "            outputs = model(inputs)             # Forward pass\n",
    "            loss = criterion(outputs, labels)   # Compute loss\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)    # Accumulate loss\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)                            # Get predictions\n",
    "            correct_predictions += torch.sum(preds == labels).item()    # Count correct predictions\n",
    "    \n",
    "    test_loss = running_loss / len(test_loader.dataset)         # Calculate average test loss\n",
    "    accuracy = correct_predictions / len(test_loader.dataset)   # Calculate test accuracy\n",
    "    \n",
    "    # Print test metrics\n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class: PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom PyTorch classifier for hyperparameter search\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Custom PyTorch classifier for hyperparameter search with scikit-learn compatibility.\n",
    "\n",
    "    Args:\n",
    "        hidden_sizes (tuple): Sizes of hidden layers.\n",
    "        dropout_prob (float): Dropout probability.\n",
    "        lr (float): Learning rate.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "        patience (int): Patience for early stopping.\n",
    "        log_dir (str): Directory to save TensorBoard logs.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_sizes=(512, 128, 64, 32), dropout_prob=0.5, lr=0.001, num_epochs=3, patience=5, log_dir=None):\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patience = patience\n",
    "        self.log_dir = log_dir\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the PyTorch model on the given dataset.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Training data features.\n",
    "            y (numpy.ndarray): Training data labels.\n",
    "\n",
    "        Returns:\n",
    "            self: Returns an instance of self.\n",
    "        \"\"\"\n",
    "        input_size = X.shape[1]         # Number of input features\n",
    "        output_size = len(np.unique(y)) # Number of unique classes\n",
    "\n",
    "        # Initialize the model\n",
    "        self.model = DroughtClassifier(input_size, self.hidden_sizes, output_size, self.dropout_prob).to(device)\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.005)\n",
    "\n",
    "        # Create DataLoader for training data\n",
    "        train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        labels_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        train_dataset = TensorDataset(train_tensor, labels_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        # Define hyperparameters for logging\n",
    "        hparams = {\n",
    "            'hidden_sizes': str(self.hidden_sizes),\n",
    "            'dropout_prob': self.dropout_prob,\n",
    "            'lr': self.lr\n",
    "        }\n",
    "\n",
    "        # Train the model\n",
    "        train_model(self.model, train_loader, val_loader, criterion, optimizer, scheduler, self.num_epochs, self.patience, log_dir=self.log_dir, hparams=hparams)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels for the given dataset.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Data features.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted labels.\n",
    "        \"\"\"\n",
    "        self.model.eval()   # Set model to evaluation mode\n",
    "        test_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        test_loader = DataLoader(test_tensor, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        predictions = []\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            for inputs in test_loader:\n",
    "                inputs = inputs.to(device)              # Move inputs to GPU\n",
    "                outputs = self.model(inputs)            # Forward pass\n",
    "                _, preds = torch.max(outputs, 1)        # Get predictions\n",
    "                predictions.extend(preds.cpu().numpy()) # Store predictions\n",
    "\n",
    "        # Return predictions as a numpy array\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Base Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_size = X_train.shape[1]  # Number of features\n",
    "hidden_sizes = [512, 128, 64, 32]   # model3.2\n",
    "\n",
    "output_size = 6                # Number of output classes\n",
    "dropout_prob = 0.5             # Dropout probability\n",
    "\n",
    "# Initialize the model\n",
    "base_model = DroughtClassifier(input_size, hidden_sizes, output_size, dropout_prob).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.005)\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "lr_space = [10**(-4 * np.random.uniform(0.5, 1)) for _ in range(5)] #learning rate values between 0.1 (1e-1) and 0.001 (1e-4)\n",
    "param_grid = {\n",
    "    'hidden_sizes': [(512, 128, 64, 32), (256, 64, 32), (512, 256, 128, 64)],\n",
    "    'dropout_prob': [0.3, 0.4, 0.5],\n",
    "    'lr': lr_space\n",
    "}\n",
    "\n",
    "# Initialize ParameterGrid\n",
    "grid = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParameterGrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_test is a numpy array\n",
    "y_test = y_test.to_numpy() if not isinstance(y_test, np.ndarray) else y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 128, 64, 32), 'lr': 0.009880946584662877}\n",
      "Epoch 1/25, Training Loss: 1.4385, Training Accuracy: 0.3794, Validation Loss: 1.3593, Validation Accuracy: 0.4048\n",
      "Epoch 2/25, Training Loss: 1.4317, Training Accuracy: 0.3818, Validation Loss: 1.3535, Validation Accuracy: 0.4053\n",
      "Epoch 3/25, Training Loss: 1.4362, Training Accuracy: 0.3816, Validation Loss: 1.3496, Validation Accuracy: 0.4124\n",
      "Epoch 4/25, Training Loss: 1.4374, Training Accuracy: 0.3801, Validation Loss: 1.3833, Validation Accuracy: 0.3773\n",
      "Epoch 5/25, Training Loss: 1.4405, Training Accuracy: 0.3776, Validation Loss: 1.3436, Validation Accuracy: 0.4067\n",
      "Epoch 6/25, Training Loss: 1.4419, Training Accuracy: 0.3764, Validation Loss: 1.3515, Validation Accuracy: 0.3570\n",
      "Epoch 7/25, Training Loss: 1.4499, Training Accuracy: 0.3741, Validation Loss: 1.3754, Validation Accuracy: 0.4056\n",
      "Epoch 8/25, Training Loss: 1.4572, Training Accuracy: 0.3720, Validation Loss: 1.3465, Validation Accuracy: 0.4046\n",
      "Epoch 9/25, Training Loss: 1.4511, Training Accuracy: 0.3743, Validation Loss: 1.3593, Validation Accuracy: 0.4097\n",
      "Epoch 10/25, Training Loss: 1.4481, Training Accuracy: 0.3756, Validation Loss: 1.3513, Validation Accuracy: 0.4061\n",
      "Early stopping at epoch 10\n",
      "Training complete\n",
      "Validation Accuracy: 0.5255\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 128, 64, 32), 'lr': 0.0035947085621553993}\n",
      "Epoch 1/25, Training Loss: 1.2883, Training Accuracy: 0.4464, Validation Loss: 1.1184, Validation Accuracy: 0.5235\n",
      "Epoch 2/25, Training Loss: 1.2086, Training Accuracy: 0.4819, Validation Loss: 1.0824, Validation Accuracy: 0.5376\n",
      "Epoch 3/25, Training Loss: 1.1840, Training Accuracy: 0.4931, Validation Loss: 1.1036, Validation Accuracy: 0.5277\n",
      "Epoch 4/25, Training Loss: 1.1730, Training Accuracy: 0.4987, Validation Loss: 1.0570, Validation Accuracy: 0.5559\n",
      "Epoch 5/25, Training Loss: 1.1634, Training Accuracy: 0.5033, Validation Loss: 1.0338, Validation Accuracy: 0.5673\n",
      "Epoch 6/25, Training Loss: 1.1566, Training Accuracy: 0.5067, Validation Loss: 1.0350, Validation Accuracy: 0.5593\n",
      "Epoch 7/25, Training Loss: 1.1507, Training Accuracy: 0.5094, Validation Loss: 1.0330, Validation Accuracy: 0.5596\n",
      "Epoch 8/25, Training Loss: 1.1478, Training Accuracy: 0.5111, Validation Loss: 1.0304, Validation Accuracy: 0.5686\n",
      "Epoch 9/25, Training Loss: 1.1448, Training Accuracy: 0.5126, Validation Loss: 1.0114, Validation Accuracy: 0.5704\n",
      "Epoch 10/25, Training Loss: 1.1415, Training Accuracy: 0.5145, Validation Loss: 1.0095, Validation Accuracy: 0.5720\n",
      "Epoch 11/25, Training Loss: 1.1230, Training Accuracy: 0.5214, Validation Loss: 0.9906, Validation Accuracy: 0.5882\n",
      "Epoch 12/25, Training Loss: 1.1101, Training Accuracy: 0.5271, Validation Loss: 0.9828, Validation Accuracy: 0.5923\n",
      "Epoch 13/25, Training Loss: 1.1034, Training Accuracy: 0.5300, Validation Loss: 0.9771, Validation Accuracy: 0.5945\n",
      "Epoch 14/25, Training Loss: 1.0986, Training Accuracy: 0.5319, Validation Loss: 0.9721, Validation Accuracy: 0.5965\n",
      "Epoch 15/25, Training Loss: 1.0950, Training Accuracy: 0.5336, Validation Loss: 0.9701, Validation Accuracy: 0.5977\n",
      "Epoch 16/25, Training Loss: 1.0925, Training Accuracy: 0.5349, Validation Loss: 0.9674, Validation Accuracy: 0.5989\n",
      "Epoch 17/25, Training Loss: 1.0903, Training Accuracy: 0.5355, Validation Loss: 0.9645, Validation Accuracy: 0.5998\n",
      "Epoch 18/25, Training Loss: 1.0880, Training Accuracy: 0.5367, Validation Loss: 0.9622, Validation Accuracy: 0.6009\n",
      "Epoch 19/25, Training Loss: 1.0865, Training Accuracy: 0.5370, Validation Loss: 0.9610, Validation Accuracy: 0.6016\n",
      "Epoch 20/25, Training Loss: 1.0848, Training Accuracy: 0.5380, Validation Loss: 0.9603, Validation Accuracy: 0.6022\n",
      "Epoch 21/25, Training Loss: 1.0845, Training Accuracy: 0.5382, Validation Loss: 0.9599, Validation Accuracy: 0.6022\n",
      "Epoch 22/25, Training Loss: 1.0842, Training Accuracy: 0.5380, Validation Loss: 0.9598, Validation Accuracy: 0.6022\n",
      "Epoch 23/25, Training Loss: 1.0842, Training Accuracy: 0.5380, Validation Loss: 0.9597, Validation Accuracy: 0.6022\n",
      "Epoch 24/25, Training Loss: 1.0841, Training Accuracy: 0.5382, Validation Loss: 0.9597, Validation Accuracy: 0.6022\n",
      "Epoch 25/25, Training Loss: 1.0843, Training Accuracy: 0.5380, Validation Loss: 0.9596, Validation Accuracy: 0.6022\n",
      "Training complete\n",
      "Validation Accuracy: 0.5874\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 128, 64, 32), 'lr': 0.00010503753799778924}\n",
      "Epoch 1/25, Training Loss: 1.4373, Training Accuracy: 0.3849, Validation Loss: 1.2520, Validation Accuracy: 0.4649\n",
      "Epoch 2/25, Training Loss: 1.2891, Training Accuracy: 0.4471, Validation Loss: 1.1514, Validation Accuracy: 0.5094\n",
      "Epoch 3/25, Training Loss: 1.2288, Training Accuracy: 0.4725, Validation Loss: 1.0965, Validation Accuracy: 0.5340\n",
      "Epoch 4/25, Training Loss: 1.1934, Training Accuracy: 0.4879, Validation Loss: 1.0644, Validation Accuracy: 0.5480\n",
      "Epoch 5/25, Training Loss: 1.1704, Training Accuracy: 0.4981, Validation Loss: 1.0382, Validation Accuracy: 0.5604\n",
      "Epoch 6/25, Training Loss: 1.1536, Training Accuracy: 0.5059, Validation Loss: 1.0195, Validation Accuracy: 0.5694\n",
      "Epoch 7/25, Training Loss: 1.1409, Training Accuracy: 0.5118, Validation Loss: 1.0055, Validation Accuracy: 0.5766\n",
      "Epoch 8/25, Training Loss: 1.1310, Training Accuracy: 0.5163, Validation Loss: 0.9956, Validation Accuracy: 0.5800\n",
      "Epoch 9/25, Training Loss: 1.1220, Training Accuracy: 0.5201, Validation Loss: 0.9893, Validation Accuracy: 0.5841\n",
      "Epoch 10/25, Training Loss: 1.1157, Training Accuracy: 0.5235, Validation Loss: 0.9781, Validation Accuracy: 0.5914\n",
      "Epoch 11/25, Training Loss: 1.1092, Training Accuracy: 0.5262, Validation Loss: 0.9741, Validation Accuracy: 0.5920\n",
      "Epoch 12/25, Training Loss: 1.1067, Training Accuracy: 0.5273, Validation Loss: 0.9727, Validation Accuracy: 0.5927\n",
      "Epoch 13/25, Training Loss: 1.1056, Training Accuracy: 0.5278, Validation Loss: 0.9714, Validation Accuracy: 0.5934\n",
      "Epoch 14/25, Training Loss: 1.1049, Training Accuracy: 0.5281, Validation Loss: 0.9708, Validation Accuracy: 0.5936\n",
      "Epoch 15/25, Training Loss: 1.1042, Training Accuracy: 0.5285, Validation Loss: 0.9703, Validation Accuracy: 0.5938\n",
      "Epoch 16/25, Training Loss: 1.1039, Training Accuracy: 0.5287, Validation Loss: 0.9696, Validation Accuracy: 0.5942\n",
      "Epoch 17/25, Training Loss: 1.1033, Training Accuracy: 0.5288, Validation Loss: 0.9692, Validation Accuracy: 0.5943\n",
      "Epoch 18/25, Training Loss: 1.1030, Training Accuracy: 0.5290, Validation Loss: 0.9688, Validation Accuracy: 0.5944\n",
      "Epoch 19/25, Training Loss: 1.1031, Training Accuracy: 0.5289, Validation Loss: 0.9686, Validation Accuracy: 0.5947\n",
      "Epoch 20/25, Training Loss: 1.1024, Training Accuracy: 0.5295, Validation Loss: 0.9683, Validation Accuracy: 0.5947\n",
      "Epoch 21/25, Training Loss: 1.1025, Training Accuracy: 0.5293, Validation Loss: 0.9683, Validation Accuracy: 0.5947\n",
      "Epoch 22/25, Training Loss: 1.1023, Training Accuracy: 0.5293, Validation Loss: 0.9683, Validation Accuracy: 0.5947\n",
      "Epoch 23/25, Training Loss: 1.1026, Training Accuracy: 0.5292, Validation Loss: 0.9683, Validation Accuracy: 0.5947\n",
      "Epoch 24/25, Training Loss: 1.1024, Training Accuracy: 0.5293, Validation Loss: 0.9683, Validation Accuracy: 0.5947\n",
      "Epoch 25/25, Training Loss: 1.1021, Training Accuracy: 0.5293, Validation Loss: 0.9683, Validation Accuracy: 0.5947\n",
      "Training complete\n",
      "Validation Accuracy: 0.5993\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 128, 64, 32), 'lr': 0.004078000432960666}\n",
      "Epoch 1/25, Training Loss: 1.2952, Training Accuracy: 0.4429, Validation Loss: 1.1485, Validation Accuracy: 0.4975\n",
      "Epoch 2/25, Training Loss: 1.2218, Training Accuracy: 0.4748, Validation Loss: 1.1021, Validation Accuracy: 0.5327\n",
      "Epoch 3/25, Training Loss: 1.1983, Training Accuracy: 0.4858, Validation Loss: 1.0969, Validation Accuracy: 0.5197\n",
      "Epoch 4/25, Training Loss: 1.1868, Training Accuracy: 0.4920, Validation Loss: 1.0628, Validation Accuracy: 0.5436\n",
      "Epoch 5/25, Training Loss: 1.1775, Training Accuracy: 0.4961, Validation Loss: 1.0653, Validation Accuracy: 0.5538\n",
      "Epoch 6/25, Training Loss: 1.1720, Training Accuracy: 0.4988, Validation Loss: 1.0373, Validation Accuracy: 0.5576\n",
      "Epoch 7/25, Training Loss: 1.1656, Training Accuracy: 0.5020, Validation Loss: 1.0319, Validation Accuracy: 0.5643\n",
      "Epoch 8/25, Training Loss: 1.1629, Training Accuracy: 0.5035, Validation Loss: 1.0384, Validation Accuracy: 0.5647\n",
      "Epoch 9/25, Training Loss: 1.1600, Training Accuracy: 0.5050, Validation Loss: 1.0296, Validation Accuracy: 0.5663\n",
      "Epoch 10/25, Training Loss: 1.1570, Training Accuracy: 0.5067, Validation Loss: 1.0479, Validation Accuracy: 0.5543\n",
      "Epoch 11/25, Training Loss: 1.1354, Training Accuracy: 0.5152, Validation Loss: 1.0046, Validation Accuracy: 0.5796\n",
      "Epoch 12/25, Training Loss: 1.1225, Training Accuracy: 0.5200, Validation Loss: 0.9975, Validation Accuracy: 0.5835\n",
      "Epoch 13/25, Training Loss: 1.1156, Training Accuracy: 0.5232, Validation Loss: 0.9918, Validation Accuracy: 0.5854\n",
      "Epoch 14/25, Training Loss: 1.1111, Training Accuracy: 0.5252, Validation Loss: 0.9873, Validation Accuracy: 0.5874\n",
      "Epoch 15/25, Training Loss: 1.1076, Training Accuracy: 0.5266, Validation Loss: 0.9851, Validation Accuracy: 0.5886\n",
      "Epoch 16/25, Training Loss: 1.1052, Training Accuracy: 0.5275, Validation Loss: 0.9825, Validation Accuracy: 0.5898\n",
      "Epoch 17/25, Training Loss: 1.1025, Training Accuracy: 0.5287, Validation Loss: 0.9801, Validation Accuracy: 0.5907\n",
      "Epoch 18/25, Training Loss: 1.1003, Training Accuracy: 0.5297, Validation Loss: 0.9774, Validation Accuracy: 0.5915\n",
      "Epoch 19/25, Training Loss: 1.0986, Training Accuracy: 0.5305, Validation Loss: 0.9770, Validation Accuracy: 0.5924\n",
      "Epoch 20/25, Training Loss: 1.0972, Training Accuracy: 0.5311, Validation Loss: 0.9750, Validation Accuracy: 0.5930\n",
      "Epoch 21/25, Training Loss: 1.0964, Training Accuracy: 0.5313, Validation Loss: 0.9748, Validation Accuracy: 0.5930\n",
      "Epoch 22/25, Training Loss: 1.0964, Training Accuracy: 0.5313, Validation Loss: 0.9747, Validation Accuracy: 0.5930\n",
      "Epoch 23/25, Training Loss: 1.0963, Training Accuracy: 0.5311, Validation Loss: 0.9746, Validation Accuracy: 0.5930\n",
      "Epoch 24/25, Training Loss: 1.0963, Training Accuracy: 0.5314, Validation Loss: 0.9746, Validation Accuracy: 0.5930\n",
      "Epoch 25/25, Training Loss: 1.0964, Training Accuracy: 0.5313, Validation Loss: 0.9746, Validation Accuracy: 0.5930\n",
      "Training complete\n",
      "Validation Accuracy: 0.5827\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 128, 64, 32), 'lr': 0.00012147413409221901}\n",
      "Epoch 1/25, Training Loss: 1.4217, Training Accuracy: 0.3915, Validation Loss: 1.2329, Validation Accuracy: 0.4738\n",
      "Epoch 2/25, Training Loss: 1.2746, Training Accuracy: 0.4528, Validation Loss: 1.1351, Validation Accuracy: 0.5165\n",
      "Epoch 3/25, Training Loss: 1.2158, Training Accuracy: 0.4780, Validation Loss: 1.0854, Validation Accuracy: 0.5387\n",
      "Epoch 4/25, Training Loss: 1.1816, Training Accuracy: 0.4929, Validation Loss: 1.0486, Validation Accuracy: 0.5556\n",
      "Epoch 5/25, Training Loss: 1.1597, Training Accuracy: 0.5032, Validation Loss: 1.0246, Validation Accuracy: 0.5652\n",
      "Epoch 6/25, Training Loss: 1.1436, Training Accuracy: 0.5106, Validation Loss: 1.0090, Validation Accuracy: 0.5760\n",
      "Epoch 7/25, Training Loss: 1.1317, Training Accuracy: 0.5161, Validation Loss: 0.9947, Validation Accuracy: 0.5827\n",
      "Epoch 8/25, Training Loss: 1.1226, Training Accuracy: 0.5206, Validation Loss: 0.9837, Validation Accuracy: 0.5883\n",
      "Epoch 9/25, Training Loss: 1.1150, Training Accuracy: 0.5244, Validation Loss: 0.9768, Validation Accuracy: 0.5906\n",
      "Epoch 10/25, Training Loss: 1.1092, Training Accuracy: 0.5271, Validation Loss: 0.9692, Validation Accuracy: 0.5942\n",
      "Epoch 11/25, Training Loss: 1.1025, Training Accuracy: 0.5300, Validation Loss: 0.9643, Validation Accuracy: 0.5976\n",
      "Epoch 12/25, Training Loss: 1.1000, Training Accuracy: 0.5310, Validation Loss: 0.9626, Validation Accuracy: 0.5982\n",
      "Epoch 13/25, Training Loss: 1.0991, Training Accuracy: 0.5314, Validation Loss: 0.9616, Validation Accuracy: 0.5988\n",
      "Epoch 14/25, Training Loss: 1.0979, Training Accuracy: 0.5318, Validation Loss: 0.9607, Validation Accuracy: 0.5992\n",
      "Epoch 15/25, Training Loss: 1.0975, Training Accuracy: 0.5321, Validation Loss: 0.9598, Validation Accuracy: 0.5994\n",
      "Epoch 16/25, Training Loss: 1.0969, Training Accuracy: 0.5325, Validation Loss: 0.9595, Validation Accuracy: 0.5997\n",
      "Epoch 17/25, Training Loss: 1.0962, Training Accuracy: 0.5326, Validation Loss: 0.9590, Validation Accuracy: 0.5998\n",
      "Epoch 18/25, Training Loss: 1.0957, Training Accuracy: 0.5329, Validation Loss: 0.9585, Validation Accuracy: 0.6000\n",
      "Epoch 19/25, Training Loss: 1.0954, Training Accuracy: 0.5331, Validation Loss: 0.9582, Validation Accuracy: 0.6002\n",
      "Epoch 20/25, Training Loss: 1.0952, Training Accuracy: 0.5332, Validation Loss: 0.9577, Validation Accuracy: 0.6004\n",
      "Epoch 21/25, Training Loss: 1.0952, Training Accuracy: 0.5330, Validation Loss: 0.9578, Validation Accuracy: 0.6004\n",
      "Epoch 22/25, Training Loss: 1.0950, Training Accuracy: 0.5330, Validation Loss: 0.9578, Validation Accuracy: 0.6004\n",
      "Epoch 23/25, Training Loss: 1.0952, Training Accuracy: 0.5332, Validation Loss: 0.9578, Validation Accuracy: 0.6004\n",
      "Epoch 24/25, Training Loss: 1.0953, Training Accuracy: 0.5329, Validation Loss: 0.9578, Validation Accuracy: 0.6004\n",
      "Epoch 25/25, Training Loss: 1.0949, Training Accuracy: 0.5331, Validation Loss: 0.9578, Validation Accuracy: 0.6004\n",
      "Early stopping at epoch 25\n",
      "Training complete\n",
      "Validation Accuracy: 0.6003\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (256, 64, 32), 'lr': 0.009880946584662877}\n",
      "Epoch 1/25, Training Loss: 1.3905, Training Accuracy: 0.4006, Validation Loss: 1.2704, Validation Accuracy: 0.4469\n",
      "Epoch 2/25, Training Loss: 1.3515, Training Accuracy: 0.4159, Validation Loss: 1.2549, Validation Accuracy: 0.4504\n",
      "Epoch 3/25, Training Loss: 1.3432, Training Accuracy: 0.4186, Validation Loss: 1.3582, Validation Accuracy: 0.3824\n",
      "Epoch 4/25, Training Loss: 1.3425, Training Accuracy: 0.4179, Validation Loss: 1.2828, Validation Accuracy: 0.4457\n",
      "Epoch 5/25, Training Loss: 1.3395, Training Accuracy: 0.4195, Validation Loss: 1.2239, Validation Accuracy: 0.4673\n",
      "Epoch 6/25, Training Loss: 1.3383, Training Accuracy: 0.4202, Validation Loss: 1.2230, Validation Accuracy: 0.4656\n",
      "Epoch 7/25, Training Loss: 1.3360, Training Accuracy: 0.4212, Validation Loss: 1.2249, Validation Accuracy: 0.4700\n",
      "Epoch 8/25, Training Loss: 1.3364, Training Accuracy: 0.4217, Validation Loss: 1.2310, Validation Accuracy: 0.4510\n",
      "Epoch 9/25, Training Loss: 1.3332, Training Accuracy: 0.4240, Validation Loss: 1.2283, Validation Accuracy: 0.4759\n",
      "Epoch 10/25, Training Loss: 1.3337, Training Accuracy: 0.4255, Validation Loss: 1.2186, Validation Accuracy: 0.4704\n",
      "Epoch 11/25, Training Loss: 1.3033, Training Accuracy: 0.4411, Validation Loss: 1.1926, Validation Accuracy: 0.4886\n",
      "Epoch 12/25, Training Loss: 1.2910, Training Accuracy: 0.4460, Validation Loss: 1.1861, Validation Accuracy: 0.4922\n",
      "Epoch 13/25, Training Loss: 1.2849, Training Accuracy: 0.4484, Validation Loss: 1.1804, Validation Accuracy: 0.4945\n",
      "Epoch 14/25, Training Loss: 1.2802, Training Accuracy: 0.4503, Validation Loss: 1.1771, Validation Accuracy: 0.4967\n",
      "Epoch 15/25, Training Loss: 1.2761, Training Accuracy: 0.4521, Validation Loss: 1.1723, Validation Accuracy: 0.4984\n",
      "Epoch 16/25, Training Loss: 1.2732, Training Accuracy: 0.4530, Validation Loss: 1.1688, Validation Accuracy: 0.4999\n",
      "Epoch 17/25, Training Loss: 1.2708, Training Accuracy: 0.4540, Validation Loss: 1.1665, Validation Accuracy: 0.5008\n",
      "Epoch 18/25, Training Loss: 1.2688, Training Accuracy: 0.4551, Validation Loss: 1.1648, Validation Accuracy: 0.5021\n",
      "Epoch 19/25, Training Loss: 1.2668, Training Accuracy: 0.4557, Validation Loss: 1.1626, Validation Accuracy: 0.5031\n",
      "Epoch 20/25, Training Loss: 1.2647, Training Accuracy: 0.4567, Validation Loss: 1.1598, Validation Accuracy: 0.5040\n",
      "Epoch 21/25, Training Loss: 1.2639, Training Accuracy: 0.4576, Validation Loss: 1.1598, Validation Accuracy: 0.5041\n",
      "Epoch 22/25, Training Loss: 1.2638, Training Accuracy: 0.4573, Validation Loss: 1.1598, Validation Accuracy: 0.5041\n",
      "Epoch 23/25, Training Loss: 1.2636, Training Accuracy: 0.4575, Validation Loss: 1.1598, Validation Accuracy: 0.5041\n",
      "Epoch 24/25, Training Loss: 1.2640, Training Accuracy: 0.4574, Validation Loss: 1.1598, Validation Accuracy: 0.5041\n",
      "Epoch 25/25, Training Loss: 1.2640, Training Accuracy: 0.4572, Validation Loss: 1.1599, Validation Accuracy: 0.5041\n",
      "Training complete\n",
      "Validation Accuracy: 0.5292\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (256, 64, 32), 'lr': 0.0035947085621553993}\n",
      "Epoch 1/25, Training Loss: 1.3212, Training Accuracy: 0.4320, Validation Loss: 1.1717, Validation Accuracy: 0.4971\n",
      "Epoch 2/25, Training Loss: 1.2578, Training Accuracy: 0.4581, Validation Loss: 1.1412, Validation Accuracy: 0.5082\n",
      "Epoch 3/25, Training Loss: 1.2425, Training Accuracy: 0.4650, Validation Loss: 1.1354, Validation Accuracy: 0.5168\n",
      "Epoch 4/25, Training Loss: 1.2350, Training Accuracy: 0.4683, Validation Loss: 1.1300, Validation Accuracy: 0.5131\n",
      "Epoch 5/25, Training Loss: 1.2294, Training Accuracy: 0.4710, Validation Loss: 1.1335, Validation Accuracy: 0.5144\n",
      "Epoch 6/25, Training Loss: 1.2256, Training Accuracy: 0.4730, Validation Loss: 1.1146, Validation Accuracy: 0.5226\n",
      "Epoch 7/25, Training Loss: 1.2222, Training Accuracy: 0.4750, Validation Loss: 1.1273, Validation Accuracy: 0.4963\n",
      "Epoch 8/25, Training Loss: 1.2203, Training Accuracy: 0.4756, Validation Loss: 1.1152, Validation Accuracy: 0.5285\n",
      "Epoch 9/25, Training Loss: 1.2183, Training Accuracy: 0.4771, Validation Loss: 1.1045, Validation Accuracy: 0.5276\n",
      "Epoch 10/25, Training Loss: 1.2170, Training Accuracy: 0.4776, Validation Loss: 1.1065, Validation Accuracy: 0.5247\n",
      "Epoch 11/25, Training Loss: 1.2001, Training Accuracy: 0.4851, Validation Loss: 1.0879, Validation Accuracy: 0.5419\n",
      "Epoch 12/25, Training Loss: 1.1908, Training Accuracy: 0.4893, Validation Loss: 1.0825, Validation Accuracy: 0.5445\n",
      "Epoch 13/25, Training Loss: 1.1864, Training Accuracy: 0.4912, Validation Loss: 1.0780, Validation Accuracy: 0.5462\n",
      "Epoch 14/25, Training Loss: 1.1835, Training Accuracy: 0.4926, Validation Loss: 1.0757, Validation Accuracy: 0.5474\n",
      "Epoch 15/25, Training Loss: 1.1814, Training Accuracy: 0.4933, Validation Loss: 1.0734, Validation Accuracy: 0.5482\n",
      "Epoch 16/25, Training Loss: 1.1797, Training Accuracy: 0.4942, Validation Loss: 1.0724, Validation Accuracy: 0.5490\n",
      "Epoch 17/25, Training Loss: 1.1785, Training Accuracy: 0.4949, Validation Loss: 1.0707, Validation Accuracy: 0.5496\n",
      "Epoch 18/25, Training Loss: 1.1776, Training Accuracy: 0.4951, Validation Loss: 1.0696, Validation Accuracy: 0.5502\n",
      "Epoch 19/25, Training Loss: 1.1763, Training Accuracy: 0.4956, Validation Loss: 1.0680, Validation Accuracy: 0.5507\n",
      "Epoch 20/25, Training Loss: 1.1757, Training Accuracy: 0.4961, Validation Loss: 1.0676, Validation Accuracy: 0.5512\n",
      "Epoch 21/25, Training Loss: 1.1751, Training Accuracy: 0.4961, Validation Loss: 1.0675, Validation Accuracy: 0.5512\n",
      "Epoch 22/25, Training Loss: 1.1753, Training Accuracy: 0.4962, Validation Loss: 1.0675, Validation Accuracy: 0.5511\n",
      "Epoch 23/25, Training Loss: 1.1753, Training Accuracy: 0.4962, Validation Loss: 1.0675, Validation Accuracy: 0.5512\n",
      "Epoch 24/25, Training Loss: 1.1754, Training Accuracy: 0.4962, Validation Loss: 1.0675, Validation Accuracy: 0.5512\n",
      "Epoch 25/25, Training Loss: 1.1750, Training Accuracy: 0.4963, Validation Loss: 1.0675, Validation Accuracy: 0.5512\n",
      "Training complete\n",
      "Validation Accuracy: 0.5514\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (256, 64, 32), 'lr': 0.00010503753799778924}\n",
      "Epoch 1/25, Training Loss: 1.4824, Training Accuracy: 0.3668, Validation Loss: 1.3203, Validation Accuracy: 0.4362\n",
      "Epoch 2/25, Training Loss: 1.3490, Training Accuracy: 0.4211, Validation Loss: 1.2399, Validation Accuracy: 0.4703\n",
      "Epoch 3/25, Training Loss: 1.3029, Training Accuracy: 0.4398, Validation Loss: 1.1988, Validation Accuracy: 0.4881\n",
      "Epoch 4/25, Training Loss: 1.2770, Training Accuracy: 0.4509, Validation Loss: 1.1707, Validation Accuracy: 0.5004\n",
      "Epoch 5/25, Training Loss: 1.2599, Training Accuracy: 0.4582, Validation Loss: 1.1527, Validation Accuracy: 0.5080\n",
      "Epoch 6/25, Training Loss: 1.2473, Training Accuracy: 0.4636, Validation Loss: 1.1370, Validation Accuracy: 0.5152\n",
      "Epoch 7/25, Training Loss: 1.2375, Training Accuracy: 0.4674, Validation Loss: 1.1262, Validation Accuracy: 0.5206\n",
      "Epoch 8/25, Training Loss: 1.2298, Training Accuracy: 0.4708, Validation Loss: 1.1156, Validation Accuracy: 0.5251\n",
      "Epoch 9/25, Training Loss: 1.2233, Training Accuracy: 0.4733, Validation Loss: 1.1091, Validation Accuracy: 0.5281\n",
      "Epoch 10/25, Training Loss: 1.2178, Training Accuracy: 0.4755, Validation Loss: 1.1036, Validation Accuracy: 0.5299\n",
      "Epoch 11/25, Training Loss: 1.2136, Training Accuracy: 0.4770, Validation Loss: 1.1008, Validation Accuracy: 0.5318\n",
      "Epoch 12/25, Training Loss: 1.2121, Training Accuracy: 0.4779, Validation Loss: 1.0998, Validation Accuracy: 0.5324\n",
      "Epoch 13/25, Training Loss: 1.2119, Training Accuracy: 0.4780, Validation Loss: 1.0993, Validation Accuracy: 0.5327\n",
      "Epoch 14/25, Training Loss: 1.2111, Training Accuracy: 0.4781, Validation Loss: 1.0988, Validation Accuracy: 0.5329\n",
      "Epoch 15/25, Training Loss: 1.2110, Training Accuracy: 0.4784, Validation Loss: 1.0985, Validation Accuracy: 0.5331\n",
      "Epoch 16/25, Training Loss: 1.2106, Training Accuracy: 0.4789, Validation Loss: 1.0982, Validation Accuracy: 0.5333\n",
      "Epoch 17/25, Training Loss: 1.2105, Training Accuracy: 0.4787, Validation Loss: 1.0979, Validation Accuracy: 0.5335\n",
      "Epoch 18/25, Training Loss: 1.2103, Training Accuracy: 0.4787, Validation Loss: 1.0977, Validation Accuracy: 0.5336\n",
      "Epoch 19/25, Training Loss: 1.2100, Training Accuracy: 0.4788, Validation Loss: 1.0975, Validation Accuracy: 0.5337\n",
      "Epoch 20/25, Training Loss: 1.2098, Training Accuracy: 0.4788, Validation Loss: 1.0972, Validation Accuracy: 0.5338\n",
      "Epoch 21/25, Training Loss: 1.2097, Training Accuracy: 0.4788, Validation Loss: 1.0972, Validation Accuracy: 0.5338\n",
      "Epoch 22/25, Training Loss: 1.2094, Training Accuracy: 0.4791, Validation Loss: 1.0972, Validation Accuracy: 0.5338\n",
      "Epoch 23/25, Training Loss: 1.2100, Training Accuracy: 0.4789, Validation Loss: 1.0972, Validation Accuracy: 0.5338\n",
      "Epoch 24/25, Training Loss: 1.2099, Training Accuracy: 0.4791, Validation Loss: 1.0972, Validation Accuracy: 0.5338\n",
      "Epoch 25/25, Training Loss: 1.2098, Training Accuracy: 0.4791, Validation Loss: 1.0972, Validation Accuracy: 0.5338\n",
      "Early stopping at epoch 25\n",
      "Training complete\n",
      "Validation Accuracy: 0.5513\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (256, 64, 32), 'lr': 0.004078000432960666}\n",
      "Epoch 1/25, Training Loss: 1.3265, Training Accuracy: 0.4280, Validation Loss: 1.1751, Validation Accuracy: 0.4920\n",
      "Epoch 2/25, Training Loss: 1.2645, Training Accuracy: 0.4538, Validation Loss: 1.1537, Validation Accuracy: 0.5029\n",
      "Epoch 3/25, Training Loss: 1.2496, Training Accuracy: 0.4610, Validation Loss: 1.1363, Validation Accuracy: 0.5075\n",
      "Epoch 4/25, Training Loss: 1.2426, Training Accuracy: 0.4643, Validation Loss: 1.1335, Validation Accuracy: 0.5142\n",
      "Epoch 5/25, Training Loss: 1.2367, Training Accuracy: 0.4669, Validation Loss: 1.1319, Validation Accuracy: 0.5141\n",
      "Epoch 6/25, Training Loss: 1.2317, Training Accuracy: 0.4691, Validation Loss: 1.1179, Validation Accuracy: 0.5214\n",
      "Epoch 7/25, Training Loss: 1.2279, Training Accuracy: 0.4709, Validation Loss: 1.1196, Validation Accuracy: 0.5266\n",
      "Epoch 8/25, Training Loss: 1.2245, Training Accuracy: 0.4727, Validation Loss: 1.1093, Validation Accuracy: 0.5187\n",
      "Epoch 9/25, Training Loss: 1.2232, Training Accuracy: 0.4735, Validation Loss: 1.1028, Validation Accuracy: 0.5305\n",
      "Epoch 10/25, Training Loss: 1.2214, Training Accuracy: 0.4745, Validation Loss: 1.1269, Validation Accuracy: 0.5171\n",
      "Epoch 11/25, Training Loss: 1.2030, Training Accuracy: 0.4833, Validation Loss: 1.0865, Validation Accuracy: 0.5412\n",
      "Epoch 12/25, Training Loss: 1.1930, Training Accuracy: 0.4877, Validation Loss: 1.0797, Validation Accuracy: 0.5437\n",
      "Epoch 13/25, Training Loss: 1.1885, Training Accuracy: 0.4895, Validation Loss: 1.0755, Validation Accuracy: 0.5454\n",
      "Epoch 14/25, Training Loss: 1.1853, Training Accuracy: 0.4906, Validation Loss: 1.0725, Validation Accuracy: 0.5467\n",
      "Epoch 15/25, Training Loss: 1.1831, Training Accuracy: 0.4916, Validation Loss: 1.0713, Validation Accuracy: 0.5475\n",
      "Epoch 16/25, Training Loss: 1.1810, Training Accuracy: 0.4923, Validation Loss: 1.0690, Validation Accuracy: 0.5480\n",
      "Epoch 17/25, Training Loss: 1.1797, Training Accuracy: 0.4930, Validation Loss: 1.0668, Validation Accuracy: 0.5488\n",
      "Epoch 18/25, Training Loss: 1.1786, Training Accuracy: 0.4935, Validation Loss: 1.0657, Validation Accuracy: 0.5496\n",
      "Epoch 19/25, Training Loss: 1.1779, Training Accuracy: 0.4939, Validation Loss: 1.0654, Validation Accuracy: 0.5503\n",
      "Epoch 20/25, Training Loss: 1.1769, Training Accuracy: 0.4941, Validation Loss: 1.0638, Validation Accuracy: 0.5508\n",
      "Epoch 21/25, Training Loss: 1.1765, Training Accuracy: 0.4944, Validation Loss: 1.0639, Validation Accuracy: 0.5508\n",
      "Epoch 22/25, Training Loss: 1.1763, Training Accuracy: 0.4944, Validation Loss: 1.0640, Validation Accuracy: 0.5508\n",
      "Epoch 23/25, Training Loss: 1.1762, Training Accuracy: 0.4946, Validation Loss: 1.0641, Validation Accuracy: 0.5508\n",
      "Epoch 24/25, Training Loss: 1.1763, Training Accuracy: 0.4944, Validation Loss: 1.0641, Validation Accuracy: 0.5508\n",
      "Epoch 25/25, Training Loss: 1.1765, Training Accuracy: 0.4946, Validation Loss: 1.0641, Validation Accuracy: 0.5508\n",
      "Early stopping at epoch 25\n",
      "Training complete\n",
      "Validation Accuracy: 0.5448\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (256, 64, 32), 'lr': 0.00012147413409221901}\n",
      "Epoch 1/25, Training Loss: 1.4675, Training Accuracy: 0.3724, Validation Loss: 1.2997, Validation Accuracy: 0.4431\n",
      "Epoch 2/25, Training Loss: 1.3346, Training Accuracy: 0.4266, Validation Loss: 1.2200, Validation Accuracy: 0.4792\n",
      "Epoch 3/25, Training Loss: 1.2917, Training Accuracy: 0.4442, Validation Loss: 1.1836, Validation Accuracy: 0.4945\n",
      "Epoch 4/25, Training Loss: 1.2698, Training Accuracy: 0.4531, Validation Loss: 1.1618, Validation Accuracy: 0.5039\n",
      "Epoch 5/25, Training Loss: 1.2545, Training Accuracy: 0.4595, Validation Loss: 1.1442, Validation Accuracy: 0.5118\n",
      "Epoch 6/25, Training Loss: 1.2419, Training Accuracy: 0.4648, Validation Loss: 1.1295, Validation Accuracy: 0.5176\n",
      "Epoch 7/25, Training Loss: 1.2319, Training Accuracy: 0.4690, Validation Loss: 1.1215, Validation Accuracy: 0.5224\n",
      "Epoch 8/25, Training Loss: 1.2248, Training Accuracy: 0.4722, Validation Loss: 1.1092, Validation Accuracy: 0.5278\n",
      "Epoch 9/25, Training Loss: 1.2191, Training Accuracy: 0.4745, Validation Loss: 1.1033, Validation Accuracy: 0.5301\n",
      "Epoch 10/25, Training Loss: 1.2142, Training Accuracy: 0.4766, Validation Loss: 1.0980, Validation Accuracy: 0.5330\n",
      "Epoch 11/25, Training Loss: 1.2102, Training Accuracy: 0.4786, Validation Loss: 1.0947, Validation Accuracy: 0.5344\n",
      "Epoch 12/25, Training Loss: 1.2084, Training Accuracy: 0.4793, Validation Loss: 1.0937, Validation Accuracy: 0.5349\n",
      "Epoch 13/25, Training Loss: 1.2073, Training Accuracy: 0.4799, Validation Loss: 1.0929, Validation Accuracy: 0.5350\n",
      "Epoch 14/25, Training Loss: 1.2073, Training Accuracy: 0.4797, Validation Loss: 1.0925, Validation Accuracy: 0.5354\n",
      "Epoch 15/25, Training Loss: 1.2065, Training Accuracy: 0.4800, Validation Loss: 1.0921, Validation Accuracy: 0.5354\n",
      "Epoch 16/25, Training Loss: 1.2064, Training Accuracy: 0.4800, Validation Loss: 1.0918, Validation Accuracy: 0.5357\n",
      "Epoch 17/25, Training Loss: 1.2061, Training Accuracy: 0.4804, Validation Loss: 1.0916, Validation Accuracy: 0.5356\n",
      "Epoch 18/25, Training Loss: 1.2057, Training Accuracy: 0.4803, Validation Loss: 1.0914, Validation Accuracy: 0.5357\n",
      "Epoch 19/25, Training Loss: 1.2056, Training Accuracy: 0.4804, Validation Loss: 1.0911, Validation Accuracy: 0.5359\n",
      "Epoch 20/25, Training Loss: 1.2053, Training Accuracy: 0.4804, Validation Loss: 1.0910, Validation Accuracy: 0.5359\n",
      "Epoch 21/25, Training Loss: 1.2054, Training Accuracy: 0.4806, Validation Loss: 1.0910, Validation Accuracy: 0.5359\n",
      "Epoch 22/25, Training Loss: 1.2054, Training Accuracy: 0.4807, Validation Loss: 1.0910, Validation Accuracy: 0.5360\n",
      "Epoch 23/25, Training Loss: 1.2053, Training Accuracy: 0.4803, Validation Loss: 1.0910, Validation Accuracy: 0.5359\n",
      "Epoch 24/25, Training Loss: 1.2053, Training Accuracy: 0.4804, Validation Loss: 1.0910, Validation Accuracy: 0.5359\n",
      "Epoch 25/25, Training Loss: 1.2054, Training Accuracy: 0.4806, Validation Loss: 1.0910, Validation Accuracy: 0.5359\n",
      "Early stopping at epoch 25\n",
      "Training complete\n",
      "Validation Accuracy: 0.5554\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 256, 128, 64), 'lr': 0.009880946584662877}\n",
      "Epoch 1/25, Training Loss: 1.4472, Training Accuracy: 0.3768, Validation Loss: 1.3877, Validation Accuracy: 0.4056\n",
      "Epoch 2/25, Training Loss: 1.4405, Training Accuracy: 0.3788, Validation Loss: 1.3643, Validation Accuracy: 0.4124\n",
      "Epoch 3/25, Training Loss: 1.4463, Training Accuracy: 0.3772, Validation Loss: 1.4326, Validation Accuracy: 0.3721\n",
      "Epoch 4/25, Training Loss: 1.4570, Training Accuracy: 0.3716, Validation Loss: 1.3953, Validation Accuracy: 0.3978\n",
      "Epoch 5/25, Training Loss: 1.4549, Training Accuracy: 0.3710, Validation Loss: 1.3603, Validation Accuracy: 0.4041\n",
      "Epoch 6/25, Training Loss: 1.4589, Training Accuracy: 0.3678, Validation Loss: 1.3455, Validation Accuracy: 0.3953\n",
      "Epoch 7/25, Training Loss: 1.4826, Training Accuracy: 0.3559, Validation Loss: 1.3669, Validation Accuracy: 0.3949\n",
      "Epoch 8/25, Training Loss: 1.4854, Training Accuracy: 0.3573, Validation Loss: 1.3935, Validation Accuracy: 0.3558\n",
      "Epoch 9/25, Training Loss: 1.4840, Training Accuracy: 0.3579, Validation Loss: 1.4364, Validation Accuracy: 0.3888\n",
      "Epoch 10/25, Training Loss: 1.4857, Training Accuracy: 0.3606, Validation Loss: 1.4202, Validation Accuracy: 0.3893\n",
      "Epoch 11/25, Training Loss: 1.4648, Training Accuracy: 0.3705, Validation Loss: 1.3724, Validation Accuracy: 0.3949\n",
      "Early stopping at epoch 11\n",
      "Training complete\n",
      "Validation Accuracy: 0.5413\n",
      "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 256, 128, 64), 'lr': 0.0035947085621553993}\n",
      "Epoch 1/25, Training Loss: 1.2575, Training Accuracy: 0.4604, Validation Loss: 1.0732, Validation Accuracy: 0.5354\n",
      "Epoch 2/25, Training Loss: 1.1737, Training Accuracy: 0.4983, Validation Loss: 1.0417, Validation Accuracy: 0.5465\n",
      "Epoch 3/25, Training Loss: 1.1508, Training Accuracy: 0.5097, Validation Loss: 1.0273, Validation Accuracy: 0.5653\n",
      "Epoch 4/25, Training Loss: 1.1386, Training Accuracy: 0.5156, Validation Loss: 1.0933, Validation Accuracy: 0.5041\n",
      "Epoch 5/25, Training Loss: 1.1322, Training Accuracy: 0.5195, Validation Loss: 0.9877, Validation Accuracy: 0.5772\n",
      "Epoch 6/25, Training Loss: 1.1248, Training Accuracy: 0.5231, Validation Loss: 0.9874, Validation Accuracy: 0.5837\n",
      "Epoch 7/25, Training Loss: 1.1205, Training Accuracy: 0.5252, Validation Loss: 1.0266, Validation Accuracy: 0.5666\n",
      "Epoch 8/25, Training Loss: 1.1172, Training Accuracy: 0.5271, Validation Loss: 0.9817, Validation Accuracy: 0.5859\n",
      "Epoch 9/25, Training Loss: 1.1113, Training Accuracy: 0.5297, Validation Loss: 0.9912, Validation Accuracy: 0.5859\n",
      "Epoch 10/25, Training Loss: 1.1099, Training Accuracy: 0.5308, Validation Loss: 0.9805, Validation Accuracy: 0.5740\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each hyperparameter combination\n",
    "best_model = None\n",
    "best_params = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "for params in grid:\n",
    "    # Print the current hyperparameter combination being trained\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "\n",
    "    # Generate a unique log directory for each iteration\n",
    "    log_dir = get_log_dir()\n",
    "\n",
    "    # Create a PyTorchClassifier model with the current hyperparameters\n",
    "    model = PyTorchClassifier(hidden_sizes=params['hidden_sizes'],dropout_prob=params['dropout_prob'],lr=params['lr'],num_epochs=25,patience=5,log_dir=log_dir)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_predictions = model.predict(X_test)\n",
    "    val_accuracy = accuracy_score(y_test, val_predictions)\n",
    "\n",
    "    # Print the validation accuracy for the current hyperparameters\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Update the best model and parameters if the current model performs better\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model = model\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training with parameters: {'dropout_prob': 0.3, 'hidden_sizes': (512, 128, 64, 32), 'lr': 0.00033842788916548167}\n",
    "Epoch 1/25, Training Loss: 1.3206, Training Accuracy: 0.4338, Validation Loss: 1.1151, Validation Accuracy: 0.5228\n",
    "Epoch 2/25, Training Loss: 1.1892, Training Accuracy: 0.4896, Validation Loss: 1.0465, Validation Accuracy: 0.5545\n",
    "Epoch 3/25, Training Loss: 1.1528, Training Accuracy: 0.5061, Validation Loss: 1.0138, Validation Accuracy: 0.5714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the best model using the test set\n",
    "evaluate_model(best_model.model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RandomizedSearchCV with the custom PyTorch classifier\n",
    "torch_classifier = PyTorchClassifier(log_dir=get_log_dir())\n",
    "random_search = RandomizedSearchCV(torch_classifier, param_distributions=param_grid, n_iter=10, cv=3, random_state=42, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RandomizedSearchCV to find the best hyperparameters\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the model using the best hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "evaluate_model(best_model, test_loader, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
