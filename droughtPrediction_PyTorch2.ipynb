{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drought Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drought Prediction\n",
    "## Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay, classification_report,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, roc_curve, auc, cohen_kappa_score)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule, NearMiss\n",
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchviz import make_dot\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drought_df =  pd.read_csv('data/all_timeseries.csv')\n",
    "\n",
    "with open('data/Xy_trainTest.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "class DroughtNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the DroughtNet model.\n",
    "\n",
    "        Parameters:\n",
    "            input_dim (int): The number of input features.\n",
    "            hidden_dim (int): The number of neurons in the hidden layers.\n",
    "            output_dim (int): The number of output classes.\n",
    "        \"\"\"\n",
    "        super(DroughtNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)     # First fully connected layer\n",
    "        self.relu = nn.ReLU()                           # ReLU activation function\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)    # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)    # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the model.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output of the model.\n",
    "        \"\"\"\n",
    "        out = self.fc1(x)       # Apply first fully connected layer\n",
    "        out = self.relu(out)    # Apply ReLU activation\n",
    "        out = self.fc2(out)     # Apply second fully connected layer\n",
    "        out = self.relu(out)    # Apply ReLU activation\n",
    "        out = self.fc3(out)     # Apply output layer\n",
    "        return out\n",
    "\n",
    "# Complex Model\n",
    "class DroughtNetComplex(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the DroughtNetComplex model.\n",
    "\n",
    "        Parameters:\n",
    "            input_dim (int): The number of input features.\n",
    "            hidden_dims (list of int): A list where each element specifies the number of neurons in that hidden layer.\n",
    "            output_dim (int): The number of output classes.\n",
    "        \"\"\"\n",
    "        super(DroughtNetComplex, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])                                                                 # Input layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_dims[i], hidden_dims[i+1]) for i in range(len(hidden_dims)-1)])    # Hidden layers\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim)                                                              # Output layer\n",
    "        self.relu = nn.ReLU()                                                                                                   # ReLU activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the model. \n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output of the model.\n",
    "        \"\"\"\n",
    "        out = self.relu(self.input_layer(x))    # Apply input layer and ReLU activation\n",
    "        for layer in self.hidden_layers:\n",
    "            out = self.relu(layer(out))         # Apply each hidden layer and ReLU activation\n",
    "        out = self.output_layer(out)            # Apply output layer\n",
    "        return out\n",
    "\n",
    "# Train Model\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, patience=3):\n",
    "    \"\"\"\n",
    "    Train the given model. Early stopping based on validation loss.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): The neural network model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        test_loader (DataLoader): DataLoader for the test/validation data.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        optimizer (optim.Optimizer): Optimizer for the model.\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "        patience (int): Number of epochs to wait if validation loss stops decreasing.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Best model based on validation loss.\n",
    "        dict: A dictionary containing the training history (loss and accuracy for training and validation).\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables for early stopping\n",
    "    best_val_loss = float('inf')# Set initial best validation loss to infinity\n",
    "    current_patience = 0        # Initialize patience counter\n",
    "    best_model = None           # Initialize variable to store the best model\n",
    "    best_train_history = None   # Initialize variable to store the training history of the best model\n",
    "\n",
    "    train_history = {'loss': [], 'accuracy': [], 'validation_loss': [], 'validation_accuracy': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode, Initialize variables\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training loop\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()                       # Zero the parameter gradients\n",
    "            outputs = model(X_batch)                    # Forward pass\n",
    "            loss = criterion(outputs, y_batch)          # Compute loss\n",
    "            loss.backward()                             # Backward pass\n",
    "            optimizer.step()                            # Optimize the weights\n",
    "            running_loss += loss.item() * X_batch.size(0)  # Accumulate running loss\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)            # Get predictions\n",
    "            correct += (predicted == y_batch).sum().item()  # Count correct predictions\n",
    "            total += y_batch.size(0)                        # Count total samples\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)   # Compute epoch loss\n",
    "        epoch_accuracy = correct / total                        # Compute epoch accuracy\n",
    "        train_history['loss'].append(epoch_loss)                # Record training loss\n",
    "        train_history['accuracy'].append(epoch_accuracy)        # Record training accuracy\n",
    "        \n",
    "        # Set model to Eval mode, Initialize variables\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in test_loader:\n",
    "                outputs = model(X_val)                                  # Forward pass\n",
    "                val_loss = criterion(outputs, y_val)                    # Compute validation loss\n",
    "                val_running_loss += val_loss.item() * X_val.size(0)     # Accumulate validation running loss\n",
    "                \n",
    "                _, val_predicted = torch.max(outputs, 1)                # Get validation predictions\n",
    "                val_correct += (val_predicted == y_val).sum().item()    # Count correct validation predictions\n",
    "                val_total += y_val.size(0)                              # Count total validation samples\n",
    "        \n",
    "        val_epoch_loss = val_running_loss / len(test_loader.dataset)    # Compute validation epoch loss\n",
    "        val_epoch_accuracy = val_correct / val_total                    # Compute validation epoch accuracy\n",
    "        train_history['validation_loss'].append(val_epoch_loss)         # Record validation loss\n",
    "        train_history['validation_accuracy'].append(val_epoch_accuracy) # Record validation accuracy\n",
    "        \n",
    "        # Print statistics per epoch \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            current_patience = 0  # Reset patience counter\n",
    "            best_model = model  # Update best model\n",
    "            best_train_history = train_history  # Update best training history\n",
    "        else:\n",
    "            current_patience += 1  # Increment patience counter\n",
    "\n",
    "            if current_patience >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1} due to lack of improvement.')\n",
    "                return best_model, best_train_history  # Return the best model and its training history\n",
    "    return best_model, best_train_history  # Return the best model and its training history\n",
    "\n",
    "# Evaluate Model\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the given model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (nn.Module): The neural network model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test/validation data.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Set model to Eval mode, Initialize variables\n",
    "    model.eval()\n",
    "    y_pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, _ in test_loader:\n",
    "            outputs = model(X_batch)            # Forward pass\n",
    "            _, y_pred = torch.max(outputs, 1)   # Get predictions\n",
    "            y_pred_list.append(y_pred.numpy())  # Store predictions\n",
    "\n",
    "    y_pred = np.concatenate(y_pred_list)                                                # Concatenate all predictions\n",
    "    y_test_numpy = y_test.to_numpy() if not isinstance(y_test, np.ndarray) else y_test  # Ensure y_test is a numpy array\n",
    "    y_pred_flat = y_pred.flatten()                                                      # Flatten predictions\n",
    "\n",
    "    accuracy = accuracy_score(y_test_numpy, y_pred_flat)        # Compute accuracy\n",
    "    report = classification_report(y_test_numpy, y_pred_flat)   # Generate classification report\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_dim = X_train.shape[1]                # Input dimensions for the model, number of features in data\n",
    "hidden_dim = 128                            # Number of neurons in the hidden layer    \n",
    "output_dim = len(set(y_train.tolist()))     # Output dimensions for the model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                       # Define the loss function to be CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.0969, Accuracy: 0.5346, Validation Loss: 1.0146, Validation Accuracy: 0.5852\n",
      "Epoch 2/3, Loss: 0.9940, Accuracy: 0.5800, Validation Loss: 0.9566, Validation Accuracy: 0.6057\n",
      "Epoch 3/3, Loss: 0.9645, Accuracy: 0.5932, Validation Loss: 0.9427, Validation Accuracy: 0.6058\n",
      "Accuracy: 0.6058121034746912\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78    378320\n",
      "           1       0.32      0.43      0.37    103652\n",
      "           2       0.32      0.33      0.32     62885\n",
      "           3       0.35      0.48      0.41     38885\n",
      "           4       0.37      0.62      0.46     19776\n",
      "           5       0.45      0.84      0.59      7414\n",
      "\n",
      "    accuracy                           0.61    610932\n",
      "   macro avg       0.45      0.57      0.49    610932\n",
      "weighted avg       0.67      0.61      0.63    610932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = DroughtNet(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)    # Define the optimizer to be Adam, Learning rate to 0.001\n",
    "\n",
    "# Train the base model and evaluate it\n",
    "best_model, train_history = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=3)   # Train the model\n",
    "evaluate_model(best_model, test_loader)                                                                  # Evaluate the model\n",
    "\n",
    "# Save the trained base model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),  \n",
    "    'optimizer_state_dict': optimizer.state_dict(),  \n",
    "    'train_history': train_history,  \n",
    "}, 'saved_model.pth') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 1.1060, Accuracy: 0.5287, Validation Loss: 1.1021, Validation Accuracy: 0.5347\n",
      "Epoch 2/3, Loss: 1.0028, Accuracy: 0.5745, Validation Loss: 0.9673, Validation Accuracy: 0.5928\n",
      "Epoch 3/3, Loss: 0.9735, Accuracy: 0.5880, Validation Loss: 0.9626, Validation Accuracy: 0.6000\n",
      "Accuracy: 0.600006220004845\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78    378320\n",
      "           1       0.32      0.35      0.33    103652\n",
      "           2       0.28      0.44      0.34     62885\n",
      "           3       0.34      0.48      0.40     38885\n",
      "           4       0.38      0.64      0.48     19776\n",
      "           5       0.50      0.82      0.62      7414\n",
      "\n",
      "    accuracy                           0.60    610932\n",
      "   macro avg       0.45      0.57      0.49    610932\n",
      "weighted avg       0.67      0.60      0.63    610932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hidden dimensions and initialize the complex model\n",
    "hidden_dims = [128, 64, 32]\n",
    "model_complex = DroughtNetComplex(input_dim, hidden_dims, output_dim)   # Initialize the complex model\n",
    "optimizer_complex = optim.Adam(model_complex.parameters(), lr=0.001)    # Define same optimizer for complex model\n",
    "\n",
    "# Train/Evaluate the complex model\n",
    "best_model_complex, train_history_complex = train_model(model_complex, train_loader, test_loader, criterion, optimizer_complex, num_epochs=3)\n",
    "evaluate_model(model_complex, test_loader)\n",
    "\n",
    "# Save the trained complex model\n",
    "torch.save({\n",
    "    'model_state_dict': model_complex.state_dict(),  \n",
    "    'optimizer_state_dict': optimizer_complex.state_dict(), \n",
    "    'train_history': train_history_complex, \n",
    "}, 'saved_model2.pth')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search for Best Hidden Layer Size/Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hidden_layer_choices(num_choices, min_layers, max_layers, min_neurons, max_neurons):\n",
    "    \"\"\"\n",
    "    Generate a list of hidden layer configurations with random number of layers and neurons.\n",
    "\n",
    "    Args:\n",
    "        - num_choices (int): Number of different hidden layer configurations to generate.\n",
    "        - min_layers (int): Minimum number of hidden layers.\n",
    "        - max_layers (int): Maximum number of hidden layers.\n",
    "        - min_neurons (int): Minimum number of neurons in each hidden layer.\n",
    "        - max_neurons (int): Maximum number of neurons in each hidden layer.\n",
    "\n",
    "    Returns:\n",
    "        - hidden_layer_choices (list): List of hidden layer configurations.\n",
    "    \"\"\"\n",
    "    hidden_layer_choices = []  # Initialize an empty list to store the hidden layer configurations\n",
    "    \n",
    "    # For number of hidden layer configurations\n",
    "    for _ in range(num_choices):\n",
    "        num_layers = random.randint(min_layers, max_layers)                             # Randomly choose the number of layers\n",
    "        layers = [random.randint(min_neurons, max_neurons) for _ in range(num_layers)]  # Randomly choose neurons for each layer\n",
    "        hidden_layer_choices.append(layers)                                             # Append the configuration to the list\n",
    "    \n",
    "    return hidden_layer_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter random search space: [[550, 90, 182, 546], [468], [768], [734], [428], [292], [596, 783, 57], [352, 246, 837, 500], [160, 247, 906, 263, 751], [482], [298, 915, 562, 513], [1016, 469, 552, 558], [809, 66, 462], [111, 805], [861, 848, 967, 187, 360], [590, 15], [36], [917, 28, 706, 497, 769], [32], [285, 602], [103, 72, 294], [628, 320, 583, 689], [979, 381], [805, 687, 878, 105, 831], [588], [714, 990], [201], [836, 548, 884, 464], [899, 905, 164, 184, 748], [54], [440, 661, 887, 256], [149, 646], [120, 977, 296, 507], [263], [243], [271, 468], [772], [416, 30, 380, 206], [53, 759], [993, 45, 50, 715], [534, 607], [231, 970], [35], [591, 963], [152], [802, 291], [601], [606, 417], [975, 367, 659], [567, 673], [584, 754, 862, 679], [120, 659, 911, 691, 273], [65, 492, 328, 825, 140], [826, 927, 141], [852, 280, 132, 479], [818], [449, 329, 454], [976], [21, 656, 868], [809], [703, 23], [459, 254, 642], [277, 979], [594, 308, 15, 460, 1013], [518], [1023, 510, 890], [349, 416, 652, 571, 882], [668, 598], [888, 671, 407], [303, 392, 232], [857, 488, 395, 142, 535], [458], [93, 440, 569, 47, 678], [285, 246, 161], [966, 389, 441], [1015, 611, 539, 739], [967], [696, 936, 44, 62, 680], [569, 543, 301], [943, 828, 1002], [450, 716, 42], [962, 849], [128, 232, 339], [538, 266, 1023, 484, 616], [163, 422, 849, 856], [800, 871, 807, 772], [717, 815, 40, 593, 843], [700, 208, 924], [662, 415, 493, 687, 459], [244], [474, 107, 575, 546, 242], [502, 74, 147, 290, 511], [88], [943, 644, 526], [430, 789, 325], [177, 367, 281, 1023, 409], [406, 888, 475, 529], [116, 363, 304, 304], [407], [853, 841, 305]]\n"
     ]
    }
   ],
   "source": [
    "num_choices = 100   # Number of different hidden layer configurations to generate\n",
    "min_layers = 1      # Minimum number of hidden layers\n",
    "max_layers = 5      # Maximum number of hidden layers\n",
    "min_neurons = 8     # Minimum number of neurons in each hidden layer\n",
    "max_neurons = 1024  # Maximum number of neurons in each hidden layer\n",
    "\n",
    "# Generate hidden layer choices\n",
    "hidden_layer_choices = generate_hidden_layer_choices(num_choices, min_layers, max_layers, min_neurons, max_neurons)\n",
    "\n",
    "# Print the generated hyperparameter search space\n",
    "print(f'Hyperparameter random search space: {hidden_layer_choices}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search 1/10\n",
      "Epoch 1/3, Loss: 0.8887, Accuracy: 0.6283, Validation Loss: 0.8526, Validation Accuracy: 0.6477\n",
      "Epoch 2/3, Loss: 0.7155, Accuracy: 0.7089, Validation Loss: 0.7208, Validation Accuracy: 0.7054\n",
      "Epoch 3/3, Loss: 0.6576, Accuracy: 0.7358, Validation Loss: 0.7585, Validation Accuracy: 0.6866\n",
      "Random Search 2/10\n",
      "Epoch 1/3, Loss: 1.1729, Accuracy: 0.5067, Validation Loss: 1.0997, Validation Accuracy: 0.5410\n",
      "Epoch 2/3, Loss: 1.0554, Accuracy: 0.5566, Validation Loss: 1.0410, Validation Accuracy: 0.5808\n",
      "Epoch 3/3, Loss: 1.0276, Accuracy: 0.5688, Validation Loss: 1.0288, Validation Accuracy: 0.5774\n",
      "Random Search 3/10\n",
      "Epoch 1/3, Loss: 0.9338, Accuracy: 0.6110, Validation Loss: 0.8698, Validation Accuracy: 0.6380\n",
      "Epoch 2/3, Loss: 0.7676, Accuracy: 0.6859, Validation Loss: 0.9019, Validation Accuracy: 0.6262\n",
      "Epoch 3/3, Loss: 0.7181, Accuracy: 0.7078, Validation Loss: 0.8194, Validation Accuracy: 0.6656\n",
      "Random Search 4/10\n",
      "Epoch 1/3, Loss: 0.9546, Accuracy: 0.6002, Validation Loss: 0.9085, Validation Accuracy: 0.6213\n",
      "Epoch 2/3, Loss: 0.7934, Accuracy: 0.6725, Validation Loss: 0.8480, Validation Accuracy: 0.6515\n",
      "Epoch 3/3, Loss: 0.7432, Accuracy: 0.6946, Validation Loss: 0.8878, Validation Accuracy: 0.6305\n",
      "Random Search 5/10\n",
      "Epoch 1/3, Loss: 0.9369, Accuracy: 0.6075, Validation Loss: 0.7970, Validation Accuracy: 0.6673\n",
      "Epoch 2/3, Loss: 0.8111, Accuracy: 0.6669, Validation Loss: 0.8341, Validation Accuracy: 0.6519\n",
      "Epoch 3/3, Loss: 0.7862, Accuracy: 0.6787, Validation Loss: 0.7493, Validation Accuracy: 0.6912\n",
      "Random Search 6/10\n",
      "Epoch 1/3, Loss: 1.1558, Accuracy: 0.5141, Validation Loss: 1.1925, Validation Accuracy: 0.4871\n",
      "Epoch 2/3, Loss: 1.0284, Accuracy: 0.5687, Validation Loss: 1.1144, Validation Accuracy: 0.5508\n",
      "Epoch 3/3, Loss: 0.9945, Accuracy: 0.5835, Validation Loss: 1.0229, Validation Accuracy: 0.5874\n",
      "Random Search 7/10\n",
      "Epoch 1/3, Loss: 1.1514, Accuracy: 0.5165, Validation Loss: 1.1878, Validation Accuracy: 0.5044\n",
      "Epoch 2/3, Loss: 1.0262, Accuracy: 0.5711, Validation Loss: 1.1069, Validation Accuracy: 0.5341\n",
      "Epoch 3/3, Loss: 0.9916, Accuracy: 0.5861, Validation Loss: 0.9820, Validation Accuracy: 0.6046\n",
      "Random Search 8/10\n",
      "Epoch 1/3, Loss: 0.8738, Accuracy: 0.6369, Validation Loss: 0.7871, Validation Accuracy: 0.6797\n",
      "Epoch 2/3, Loss: 0.7103, Accuracy: 0.7141, Validation Loss: 0.7645, Validation Accuracy: 0.7012\n",
      "Epoch 3/3, Loss: 0.6835, Accuracy: 0.7361, Validation Loss: 0.7059, Validation Accuracy: 0.7138\n",
      "Random Search 9/10\n",
      "Epoch 1/3, Loss: 0.9213, Accuracy: 0.6152, Validation Loss: 0.7946, Validation Accuracy: 0.6646\n",
      "Epoch 2/3, Loss: 0.7887, Accuracy: 0.6770, Validation Loss: 0.8110, Validation Accuracy: 0.6552\n",
      "Epoch 3/3, Loss: 0.7599, Accuracy: 0.6905, Validation Loss: 0.7829, Validation Accuracy: 0.6688\n",
      "Random Search 10/10\n",
      "Epoch 1/3, Loss: 1.0190, Accuracy: 0.5707, Validation Loss: 0.9788, Validation Accuracy: 0.5872\n",
      "Epoch 2/3, Loss: 0.9014, Accuracy: 0.6250, Validation Loss: 0.8753, Validation Accuracy: 0.6351\n",
      "Epoch 3/3, Loss: 0.8711, Accuracy: 0.6388, Validation Loss: 0.8636, Validation Accuracy: 0.6403\n",
      "Best validation accuracy: 0.7138028454885322\n",
      "Best hidden dimensions: [349, 416, 652, 571, 882]\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for search\n",
    "num_searches = 10\n",
    "best_model = None\n",
    "best_val_accuracy = 0\n",
    "best_hidden_dims = None\n",
    "\n",
    "# Random search for num_searches\n",
    "for i in range(num_searches):\n",
    "    print(f\"Random Search {i+1}/{num_searches}\")                    # Print the current random search iteration\n",
    "    hidden_dims = random.choice(hidden_layer_choices)               # Choose random hidden layer dimensions\n",
    "    model = DroughtNetComplex(input_dim, hidden_dims, output_dim)   # Initialize the complex model\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)            # Initialize the optimizer\n",
    "    \n",
    "    # Train the model with early stopping and get the best model and its training history\n",
    "    best_model, train_history = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=3)\n",
    "    val_accuracy = train_history['validation_accuracy'][-1]\n",
    "    \n",
    "    # Update the best model and accuracy if current validation accuracy is better\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model = model\n",
    "        best_hidden_dims = hidden_dims\n",
    "\n",
    "# Print the best validation accuracy and corresponding hidden dimensions\n",
    "print(f\"Best validation accuracy: {best_val_accuracy}\")\n",
    "print(f\"Best hidden dimensions: {best_hidden_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.9929, Accuracy: 0.5790, Validation Loss: 0.9391, Validation Accuracy: 0.5972\n",
      "Epoch 2/100, Loss: 0.8951, Accuracy: 0.6240, Validation Loss: 0.9102, Validation Accuracy: 0.6162\n",
      "Epoch 3/100, Loss: 0.8770, Accuracy: 0.6330, Validation Loss: 0.8379, Validation Accuracy: 0.6566\n",
      "Epoch 4/100, Loss: 0.8716, Accuracy: 0.6355, Validation Loss: 0.9252, Validation Accuracy: 0.6071\n",
      "Epoch 5/100, Loss: 0.8674, Accuracy: 0.6373, Validation Loss: 0.8318, Validation Accuracy: 0.6607\n",
      "Epoch 6/100, Loss: 0.8656, Accuracy: 0.6384, Validation Loss: 0.8558, Validation Accuracy: 0.6469\n",
      "Epoch 7/100, Loss: 0.8643, Accuracy: 0.6393, Validation Loss: 0.8771, Validation Accuracy: 0.6318\n",
      "Epoch 8/100, Loss: 0.8613, Accuracy: 0.6410, Validation Loss: 0.8912, Validation Accuracy: 0.6353\n",
      "Early stopping at epoch 8 due to lack of improvement.\n",
      "Accuracy: 0.635339121211526\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.82    378320\n",
      "           1       0.38      0.18      0.24    103652\n",
      "           2       0.27      0.68      0.39     62885\n",
      "           3       0.46      0.45      0.46     38885\n",
      "           4       0.44      0.70      0.54     19776\n",
      "           5       0.68      0.78      0.73      7414\n",
      "\n",
      "    accuracy                           0.64    610932\n",
      "   macro avg       0.52      0.59      0.53    610932\n",
      "weighted avg       0.70      0.64      0.65    610932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best model with the best hidden dimensions\n",
    "# model = DroughtNetComplex(input_dim, best_hidden_dims, output_dim)  \n",
    "model = DroughtNetComplex(input_dim, [223, 584, 291], output_dim)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0025)  \n",
    "\n",
    "# Train/Evaluate the best model with more epochs and early stopping\n",
    "best_model, train_history = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=100, patience=3) \n",
    "evaluate_model(model, test_loader)                                                                  \n",
    "\n",
    "# Save the model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_history': train_history,\n",
    "}, 'saved_best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
